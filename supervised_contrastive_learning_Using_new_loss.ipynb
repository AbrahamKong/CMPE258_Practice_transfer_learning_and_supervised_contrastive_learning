{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamKong/CMPE258_Practice_transfer_learning_and_supervised_contrastive_learning/blob/main/supervised_contrastive_learning_Using_new_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrMGGhXqwldp"
      },
      "source": [
        "# Supervised Contrastive Learning Loss based Supervised Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3yWTh2Zwe_y"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6FhB0JLivyX",
        "outputId": "943f3647-bf72-461d-8259-1ccb24878d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 15.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1d75mTvhwjBj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tmNnzwuwy54"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffld3_PSw0d4",
        "outputId": "26f9741f-7be1-4041-da20-9d55400a1074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the train and test data splits\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Display shapes of train and test datasets\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf3UkZf5w24N"
      },
      "source": [
        "## Using image data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zh_qxB25w4Vt"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.02),\n",
        "        layers.RandomWidth(0.2),\n",
        "        layers.RandomHeight(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Setting the state of the normalization layer.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1rN9GQUxBk4"
      },
      "source": [
        "## Build the encoder model\n",
        "\n",
        "The encoder model takes the image as input and turns it into a 2048-dimensional\n",
        "feature vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0ztxTF9w_8b",
        "outputId": "95ed487b-6303-47e0-de60-cd38207a5465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,564,807\n",
            "Trainable params: 23,519,360\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def create_encoder():\n",
        "    resnet = keras.applications.ResNet50V2(\n",
        "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
        "    )\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    outputs = resnet(augmented)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
        "    return model\n",
        "\n",
        "\n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 265\n",
        "hidden_units = 512\n",
        "projection_units = 128\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.5\n",
        "temperature = 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHbexEwzlBlh"
      },
      "source": [
        "## Build the classification model\n",
        "\n",
        "The classification model adds a fully-connected layer on top of the encoder,\n",
        "plus a softmax layer with the target classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s57ShezrlBli"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_classifier(encoder, trainable=True):\n",
        "\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLIbetmMlBlj"
      },
      "source": [
        "## Experiment 1: Train the baseline classification model\n",
        "\n",
        "In this experiment, a baseline classifier is trained as usual, i.e., the\n",
        "encoder and the classifier parts are trained together as a single model\n",
        "to minimize the crossentropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN1cZhZSlBlj",
        "outputId": "8926d2ff-ed4c-4438-fbce-d00b344b12f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,619,025\n",
            "Trainable params: 24,573,578\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "189/189 [==============================] - 4865s 26s/step - loss: 1.9457 - sparse_categorical_accuracy: 0.2857\n",
            "Epoch 2/50\n",
            "189/189 [==============================] - 4971s 26s/step - loss: 1.5085 - sparse_categorical_accuracy: 0.4546\n",
            "Epoch 3/50\n",
            "189/189 [==============================] - 4869s 26s/step - loss: 1.3398 - sparse_categorical_accuracy: 0.5229\n",
            "Epoch 4/50\n",
            "189/189 [==============================] - 4680s 25s/step - loss: 1.2274 - sparse_categorical_accuracy: 0.5664\n",
            "Epoch 5/50\n",
            "169/189 [=========================>....] - ETA: 8:35 - loss: 1.1390 - sparse_categorical_accuracy: 0.6021"
          ]
        }
      ],
      "source": [
        "encoder = create_encoder()\n",
        "classifier = create_classifier(encoder)\n",
        "classifier.summary()\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSP2G1wjlBlj"
      },
      "source": [
        "## Experiment 2: Use supervised contrastive learning\n",
        "\n",
        "In this experiment, the model is trained in two phases. In the first phase,\n",
        "the encoder is pretrained to optimize the supervised contrastive loss,\n",
        "described in [Prannay Khosla et al.](https://arxiv.org/abs/2004.11362).\n",
        "\n",
        "In the second phase, the classifier is trained using the trained encoder with\n",
        "its weights freezed; only the weights of fully-connected layers with the\n",
        "softmax are optimized.\n",
        "\n",
        "### 1. Supervised contrastive learning loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etYGFyk1lBlk"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
        "\n",
        "\n",
        "def add_projection_head(encoder):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQMS5Mc7lBlk"
      },
      "source": [
        "### 2. Pretrain the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCX81BK8lBlk"
      },
      "outputs": [],
      "source": [
        "encoder = create_encoder()\n",
        "\n",
        "encoder_with_projection_head = add_projection_head(encoder)\n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=SupervisedContrastiveLoss(temperature),\n",
        ")\n",
        "\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "history = encoder_with_projection_head.fit(\n",
        "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt-eIaa1lBll"
      },
      "source": [
        "### 3. Train the classifier with the frozen encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5PfGpbAlBll"
      },
      "outputs": [],
      "source": [
        "classifier = create_classifier(encoder, trainable=False)\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNKEcUZxxRvX"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il30knM6xXj3"
      },
      "source": [
        "As shown in the experiments, using the supervised contrastive learning technique\n",
        "outperformed the conventional technique in terms of the test accuracy. Note that\n",
        "the same training budget (i.e., number of epochs) was given to each technique.\n",
        "Supervised contrastive learning pays off when the encoder involves a complex\n",
        "architecture, like ResNet, and multi-class problems with many labels.\n",
        "In addition, large batch sizes and multi-layer projection heads\n",
        "improve its effectiveness. See the [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)\n",
        "paper for more details.\n",
        "\n",
        "You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/supervised-contrastive-learning-cifar10) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/supervised-contrastive-learning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2GAcaGMxKcn"
      },
      "source": [
        "# Softmax based Supervised Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oobd4P-i-MUt"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85NTHY5z-LwI"
      },
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH27RbPm-P1c"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf0RBUdY-ReI"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS6IqNlX-TMP"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKNEMwAY-VS8"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2pPPrEp-W_w"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5zyBogC-Xz_"
      },
      "outputs": [],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc6oJyS6-a5M"
      },
      "outputs": [],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ATtU4tA-cd3"
      },
      "outputs": [],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN-aIc46-dd9"
      },
      "outputs": [],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B33hwAby-e9x"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfnnzMiY-gia"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHkm0ov--i2-"
      },
      "outputs": [],
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGyi8Eet-j_x"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9wB2aM3-kk8"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ckhlofE-z0Q"
      },
      "source": [
        "### Set up the layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lijGWe_k-1S5"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEUzRkJV-2_1"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L10fWmGf-4pa"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMhgpUXP-6dF"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Go6rFP-87c"
      },
      "source": [
        "### Feed the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJkOydkV--W2"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd-e4I-H-_xp"
      },
      "source": [
        "### Evaluate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIe0Mjxr_BmV"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CsTk35d_C_y"
      },
      "source": [
        "### Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCYUBkjU_EiQ"
      },
      "outputs": [],
      "source": [
        "probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3RDQqWU_FkB"
      },
      "outputs": [],
      "source": [
        "predictions = probability_model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtBQxaPz_G6M"
      },
      "outputs": [],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG6zcuqc_Hys"
      },
      "outputs": [],
      "source": [
        "np.argmax(predictions[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4l2fXH5_Izg"
      },
      "outputs": [],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0to28aTu_KB_"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  true_label = true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WQBwwn_Lwb"
      },
      "source": [
        "### Verify predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iokl1qBi_M1K"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgXOVnpq_Nzl"
      },
      "outputs": [],
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muaMxO_d_PB9"
      },
      "outputs": [],
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsxiJ4t0_Q8d"
      },
      "source": [
        "## Use the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auMn9iP9_R9_"
      },
      "outputs": [],
      "source": [
        "# Grab an image from the test dataset.\n",
        "img = test_images[1]\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wkjo43Z4_S0B"
      },
      "outputs": [],
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPO0SKmq_T9a"
      },
      "outputs": [],
      "source": [
        "predictions_single = probability_model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glrBFTGG_Uus"
      },
      "outputs": [],
      "source": [
        "plot_value_array(1, predictions_single[0], test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxGaODCH_Vqf"
      },
      "outputs": [],
      "source": [
        "np.argmax(predictions_single[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOFd4nP2xcCn"
      },
      "source": [
        "# Reference\n",
        "\n",
        "1. [supervised-contrastive-learning](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/supervised-contrastive-learning.ipynb#scrollTo=SzsWDuDklBll)\n",
        "2. [Basic classification: Classify images of clothing](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb?hl=id-IDCache)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "supervised contrastive learning  - Using new loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1HlGRIYAvlvbA//2o9Nv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}